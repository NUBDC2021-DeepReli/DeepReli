{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDWWVUDHWQe8"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, BatchNormalization, Bidirectional, CuDNNLSTM, GRU, Conv2D, ConvLSTM2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "#from keras.optimizers import Adam, SGD\n",
        "import nltk\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import LSTM,Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import re\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji90Cxutt8_N"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021/NEWSTUFF_March2022/data2022.csv')\n",
        "data1 = data\n",
        "\n",
        "data = data[['body_text_processed', 'reliability']]\n",
        "data = data.astype(str)\n",
        "df_full = data\n",
        "df_full.drop(df_full.tail(1).index,inplace=True) # drop last n rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "Aw0mqKh3c0ls",
        "outputId": "03167733-cd40-4198-a2b9-5695ead02008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  news_id                                                url                    publisher publish_date                                             author                                              title                                              image                                          body_text  news_guard_score mbfc_level political_bias country  reliability                                           combined                                body_text_processed\n",
              "0           0        0  https://www.nytimes.com/article/what-is-corona...           The New York Times   2020-01-21               ['Knvul Sheikh', 'Roni Caryn Rabin']  The Coronavirus: What Scientists Have Learned ...  https://static01.nyt.com/images/2020/03/12/sci...  \\nA novel respiratory virus that originated in...             100.0       High           Left     USA            1  The Coronavirus: What Scientists Have Learned ...  coronavirus scientist learned far. novel respi...\n",
              "1           1        1  https://www.npr.org/2020/01/22/798392172/chine...  National Public Radio (NPR)   2020-01-22                                     ['Emily Feng']  Chinese Health Officials: More Die From Newly ...  https://media.npr.org/include/images/facebook-...  Chinese Health Officials: More Die From Newly ...             100.0  Very high         Center     USA            1  Chinese Health Officials: More Die From Newly ...  chinese health official die newly identified c...\n",
              "2           2        2  https://www.theverge.com/2020/1/23/21078457/co...                    The Verge   2020-01-23                                 ['Nicole Wetsman']  Everything you need to know about the coronavi...  https://cdn.vox-cdn.com/thumbor/a9_Oz7cvSBKyal...  Public health experts around the globe are scr...             100.0       High    Left-center     USA            1  Everything you need to know about the coronavi...  everything need know coronavirus. public healt...\n",
              "3           3        3  https://www.worldhealth.net/news/novel-coronav...              WorldHealth.Net   2020-01-24                                                 []  Novel Coronavirus Cases Confirmed To Be Spread...  https://www.worldhealth.net/media/original_ima...  The first two coronavirus cases in Europe have...              30.0        Low            NaN     USA            0  Novel Coronavirus Cases Confirmed To Be Spread...  novel coronavirus case confirmed spreading. fi...\n",
              "4           4        4  https://www.theverge.com/2020/1/24/21080845/co...                    The Verge   2020-01-24  ['Nicole Wetsman', 'Zoe Schiffer', 'Jay Peters...  Coronavirus disrupts the world: updates on the...  https://cdn.vox-cdn.com/thumbor/t2gt1SmEni4Mcr...  A new coronavirus appeared in Wuhan, China, at...             100.0       High    Left-center     USA            1  Coronavirus disrupts the world: updates on the...  coronavirus disrupts world update pandemic. ne..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f044087-a63b-4e22-b524-18a1a0b760b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>news_id</th>\n",
              "      <th>url</th>\n",
              "      <th>publisher</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>author</th>\n",
              "      <th>title</th>\n",
              "      <th>image</th>\n",
              "      <th>body_text</th>\n",
              "      <th>news_guard_score</th>\n",
              "      <th>mbfc_level</th>\n",
              "      <th>political_bias</th>\n",
              "      <th>country</th>\n",
              "      <th>reliability</th>\n",
              "      <th>combined</th>\n",
              "      <th>body_text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.nytimes.com/article/what-is-corona...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2020-01-21</td>\n",
              "      <td>['Knvul Sheikh', 'Roni Caryn Rabin']</td>\n",
              "      <td>The Coronavirus: What Scientists Have Learned ...</td>\n",
              "      <td>https://static01.nyt.com/images/2020/03/12/sci...</td>\n",
              "      <td>\\nA novel respiratory virus that originated in...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>High</td>\n",
              "      <td>Left</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>The Coronavirus: What Scientists Have Learned ...</td>\n",
              "      <td>coronavirus scientist learned far. novel respi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.npr.org/2020/01/22/798392172/chine...</td>\n",
              "      <td>National Public Radio (NPR)</td>\n",
              "      <td>2020-01-22</td>\n",
              "      <td>['Emily Feng']</td>\n",
              "      <td>Chinese Health Officials: More Die From Newly ...</td>\n",
              "      <td>https://media.npr.org/include/images/facebook-...</td>\n",
              "      <td>Chinese Health Officials: More Die From Newly ...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Very high</td>\n",
              "      <td>Center</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>Chinese Health Officials: More Die From Newly ...</td>\n",
              "      <td>chinese health official die newly identified c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>https://www.theverge.com/2020/1/23/21078457/co...</td>\n",
              "      <td>The Verge</td>\n",
              "      <td>2020-01-23</td>\n",
              "      <td>['Nicole Wetsman']</td>\n",
              "      <td>Everything you need to know about the coronavi...</td>\n",
              "      <td>https://cdn.vox-cdn.com/thumbor/a9_Oz7cvSBKyal...</td>\n",
              "      <td>Public health experts around the globe are scr...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>High</td>\n",
              "      <td>Left-center</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>Everything you need to know about the coronavi...</td>\n",
              "      <td>everything need know coronavirus. public healt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.worldhealth.net/news/novel-coronav...</td>\n",
              "      <td>WorldHealth.Net</td>\n",
              "      <td>2020-01-24</td>\n",
              "      <td>[]</td>\n",
              "      <td>Novel Coronavirus Cases Confirmed To Be Spread...</td>\n",
              "      <td>https://www.worldhealth.net/media/original_ima...</td>\n",
              "      <td>The first two coronavirus cases in Europe have...</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USA</td>\n",
              "      <td>0</td>\n",
              "      <td>Novel Coronavirus Cases Confirmed To Be Spread...</td>\n",
              "      <td>novel coronavirus case confirmed spreading. fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.theverge.com/2020/1/24/21080845/co...</td>\n",
              "      <td>The Verge</td>\n",
              "      <td>2020-01-24</td>\n",
              "      <td>['Nicole Wetsman', 'Zoe Schiffer', 'Jay Peters...</td>\n",
              "      <td>Coronavirus disrupts the world: updates on the...</td>\n",
              "      <td>https://cdn.vox-cdn.com/thumbor/t2gt1SmEni4Mcr...</td>\n",
              "      <td>A new coronavirus appeared in Wuhan, China, at...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>High</td>\n",
              "      <td>Left-center</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>Coronavirus disrupts the world: updates on the...</td>\n",
              "      <td>coronavirus disrupts world update pandemic. ne...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f044087-a63b-4e22-b524-18a1a0b760b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f044087-a63b-4e22-b524-18a1a0b760b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f044087-a63b-4e22-b524-18a1a0b760b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBEJtKrTx8r-"
      },
      "outputs": [],
      "source": [
        "max_fatures = 20000 \n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ', oov_token='<unw>')\n",
        "tokenizer.fit_on_texts(df_full['body_text_processed'].values)\n",
        "X = tokenizer.texts_to_sequences(df_full['body_text_processed'].values)\n",
        "X = pad_sequences(X, padding = 'post', maxlen = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCty0llF-fou"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkNiUKDLhVfJ"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021/glove.6B.100d.txt', encoding=\"utf8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBvyEPY1X-_Z"
      },
      "outputs": [],
      "source": [
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVElIbeyYV4q"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVCnF9G9To1F"
      },
      "outputs": [],
      "source": [
        "Y = (df_full['reliability']).values\n",
        "Y = Y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SiF72Niys4f"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZvykW5mxma7"
      },
      "outputs": [],
      "source": [
        "#BiLSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=X.shape[1], trainable=True))\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(Bidirectional(CuDNNLSTM(50)))\n",
        "#model.add(layer = Dropout(rate = 0.4))\n",
        "# model.add(Bidirectional(CuDNNLSTM(50)))\n",
        "# model.add(layer = Dropout(rate = 0.4))\n",
        "#model.add(layer = BatchNormalization())\n",
        "#model.add(layer = Dense(units = 100,  activation = 'relu'))\n",
        "model.add(layer = BatchNormalization())\n",
        "model.add(layer = Dropout(rate = 0.4))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eYE-ZQuzzev"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "history = model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_split=0.2)\n",
        "#+20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSYJRRNzIOLB"
      },
      "outputs": [],
      "source": [
        "#CNN\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=X.shape[1], trainable=True))\n",
        "model1.add(SpatialDropout1D(0.2))\n",
        "\n",
        "model1.add(Conv1D(filters=100,\n",
        "                        kernel_size=4,\n",
        "                        activation='relu', padding=\"same\", kernel_regularizer = tf.keras.regularizers.l2(l2=0.001)))\n",
        "model1.add(layer = BatchNormalization())\n",
        "model1.add(MaxPooling1D(pool_size=2, padding = 'same'))\n",
        "model1.add(layer = Dropout(rate = 0.2))\n",
        "model1.add(Flatten())\n",
        "model1.add(layer = Dense(units = 100,  activation = 'relu'))\n",
        "model1.add(layer = Dropout(rate = 0.2))\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model1.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
        "print(model1.summary())\n",
        "#, dropout=0.4, recurrent_dropout=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42k_kARzJVxa"
      },
      "outputs": [],
      "source": [
        "batch_size = 2 \n",
        "history1 = model1.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL8pgwraLOku"
      },
      "outputs": [],
      "source": [
        "#LSTM\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=X.shape[1], trainable=True))\n",
        "model2.add(SpatialDropout1D(0.25))\n",
        "model2.add(LSTM(100))\n",
        "\n",
        "model2.add(layer = Dropout(rate = 0.5))\n",
        "# model.add(Bidirectional(CuDNNLSTM(50)))\n",
        "# model.add(layer = Dropout(rate = 0.4))\n",
        "#model.add(layer = BatchNormalization())\n",
        "#model2.add(layer = Dense(units = 100,  activation = 'relu'))\n",
        "#model.add(layer = BatchNormalization())\n",
        "#model.add(layer = Dropout(rate = 0.1))\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = Adam(learning_rate=0.005)\n",
        "model2.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
        "print(model2.summary())\n",
        "#, dropout=0.4, recurrent_dropout=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZJaV1ABLer7"
      },
      "outputs": [],
      "source": [
        "batch_size = 128 \n",
        "history2 = model2.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8lNgd2oSmxz"
      },
      "outputs": [],
      "source": [
        "#BiGRU\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=X.shape[1], trainable=True))\n",
        "model3.add(SpatialDropout1D(0.3))\n",
        "model3.add(Bidirectional(GRU(50)))\n",
        "model3.add(layer = Dropout(rate = 0.3))\n",
        "#model.add(layer = Dense(units = 100,  activation = 'relu'))\n",
        "#model.add(layer = BatchNormalization())\n",
        "#model.add(layer = Dropout(rate = 0.1))\n",
        "model3.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model3.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
        "print(model3.summary())\n",
        "#, dropout=0.4, recurrent_dropout=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwObDUsAS3GL"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "history3 = model3.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6mjoM7QXZeb"
      },
      "outputs": [],
      "source": [
        "#GRU\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=X.shape[1], trainable=True))\n",
        "model4.add(SpatialDropout1D(0.3))\n",
        "model4.add((GRU(100)))\n",
        "model4.add(layer = Dropout(rate = 0.5))\n",
        "# model.add(Bidirectional(CuDNNLSTM(50)))\n",
        "# model.add(layer = Dropout(rate = 0.4))\n",
        "#model.add(layer = BatchNormalization())\n",
        "#model.add(layer = Dense(units = 100,  activation = 'relu'))\n",
        "#model.add(layer = BatchNormalization())\n",
        "#model.add(layer = Dropout(rate = 0.1))\n",
        "model4.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = Adam(learning_rate=0.005)\n",
        "model4.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
        "print(model4.summary())\n",
        "#, dropout=0.4, recurrent_dropout=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn7wu37dXdVA"
      },
      "outputs": [],
      "source": [
        "batch_size = 128 \n",
        "history4 = model4.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmOI4-BHmsQ4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "y_pred_keras = model.predict(X_test)\n",
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_test, y_pred_keras)\n",
        "auc_keras = auc(fpr_keras, tpr_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0aGJ3oZgsWD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_bool = y_pred_keras.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdaB--dgX6zj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y00B5Ije5fQo"
      },
      "outputs": [],
      "source": [
        "y_pred_keras1 = model1.predict(X_test)\n",
        "fpr_keras1, tpr_keras1, thresholds_keras1 = roc_curve(Y_test, y_pred_keras1)\n",
        "auc_keras1 = auc(fpr_keras1, tpr_keras1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGprYTVFiHkV"
      },
      "outputs": [],
      "source": [
        "y_pred_bool = y_pred_keras1.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kLRhpY8YvLc"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Lnqxd45gDA"
      },
      "outputs": [],
      "source": [
        "y_pred_keras2 = model2.predict(X_test)\n",
        "fpr_keras2, tpr_keras2, thresholds_keras2 = roc_curve(Y_test, y_pred_keras2)\n",
        "auc_keras2 = auc(fpr_keras2, tpr_keras2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "984aj57ciJcP"
      },
      "outputs": [],
      "source": [
        "y_pred_bool = y_pred_keras2.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9WnPJliYwKX"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsLoCOTj5gg_"
      },
      "outputs": [],
      "source": [
        "y_pred_keras3 = model3.predict(X_test)\n",
        "fpr_keras3, tpr_keras3, thresholds_keras3 = roc_curve(Y_test, y_pred_keras3)\n",
        "auc_keras3 = auc(fpr_keras3, tpr_keras3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L88IljHiLw0"
      },
      "outputs": [],
      "source": [
        "y_pred_bool = y_pred_keras3.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baZWQOImYxLs"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9y_EEZi5g93"
      },
      "outputs": [],
      "source": [
        "y_pred_keras4 = model4.predict(X_test)\n",
        "fpr_keras4, tpr_keras4, thresholds_keras4 = roc_curve(Y_test, y_pred_keras4)\n",
        "auc_keras4 = auc(fpr_keras4, tpr_keras4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUSbVVWViM_F"
      },
      "outputs": [],
      "source": [
        "y_pred_bool = y_pred_keras4.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDFbkG4kYyDw"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mihZcLXJk6g"
      },
      "outputs": [],
      "source": [
        "model_results = pd.DataFrame()\n",
        "model_results['test'] = Y_test\n",
        "model_results['0'] = y_pred_keras\n",
        "model_results['1'] = y_pred_keras1\n",
        "model_results['2'] = y_pred_keras2\n",
        "model_results['3'] = y_pred_keras3\n",
        "model_results['4'] = y_pred_keras4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIIrlKGrJ_cd"
      },
      "outputs": [],
      "source": [
        "model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTr_kzAsMoK-"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(X_train, Y_train)\n",
        "# predict the labels on validation dataset\n",
        "#predictions_NB = Naive.predict(X_test1)\n",
        "predictions_NB = Naive.predict_proba(X_test)\n",
        "predictions_NB = predictions_NB[:,1]\n",
        "# Use accuracy_score function to get the accuracy\n",
        "#print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Y_test)*100)\n",
        "fpr_keras_NB, tpr_keras_NB, thresholds_keras_NB = roc_curve(Y_test, predictions_NB)\n",
        "auc_keras_NB = auc(fpr_keras_NB, tpr_keras_NB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St7rC0cWCKiP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred_bool = predictions_NB.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdJzlVL-bdQi"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYs27XFHFlUC"
      },
      "outputs": [],
      "source": [
        "predictions_NB.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uGYOZmYeHem"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier()\n",
        "KNN.fit(X_train, Y_train)\n",
        "# predict the labels on validation dataset\n",
        "predictions_KNN = KNN.predict_proba(X_test)\n",
        "predictions_KNN = predictions_KNN[:,1]\n",
        "# Use accuracy_score function to get the accuracy\n",
        "#print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Y_test)*100)\n",
        "fpr_keras_KNN, tpr_keras_KNN, thresholds_keras_KNN = roc_curve(Y_test, predictions_KNN)\n",
        "auc_keras_KNN = auc(fpr_keras_KNN, tpr_keras_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOXTw_DxCTLZ"
      },
      "outputs": [],
      "source": [
        "y_pred_bool = predictions_KNN.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj-kHQfHbwM7"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdTlZo_oyFA5"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(max_iter = 4000,class_weight='balanced')\n",
        "LR.fit(X_train, Y_train)\n",
        "# predict the labels on validation dataset\n",
        "predictions_LR = LR.predict_proba(X_test)\n",
        "predictions_LR = predictions_LR[:,1]\n",
        "# Use accuracy_score function to get the accuracy\n",
        "#print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Y_test)*100)\n",
        "fpr_keras_LR, tpr_keras_LR, thresholds_keras_LR = roc_curve(Y_test, predictions_LR)\n",
        "auc_keras_LR = auc(fpr_keras_LR, tpr_keras_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRNMJEZjbS7_"
      },
      "outputs": [],
      "source": [
        "predictions_LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4wNYXTlCU_R"
      },
      "outputs": [],
      "source": [
        "y_pred_bool = predictions_LR.round()\n",
        "\n",
        "print(classification_report(Y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXRotgbub7RN"
      },
      "outputs": [],
      "source": [
        "precision, recall, fscore, support = score(Y_test, y_pred_bool, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRpLV5ieNgzi"
      },
      "outputs": [],
      "source": [
        "# SVM = svm.SVC(kernel='linear', probability = True)\n",
        "# SVM.fit(X_train,Y_train)\n",
        "# # predict the labels on validation dataset\n",
        "# predictions_SVM = SVM.predict_proba(X_test)\n",
        "# predictions_SVM = predictions_SVM[:,0]\n",
        "# # Use accuracy_score function to get the accuracy\n",
        "# #print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
        "# fpr_keras_SVM, tpr_keras_SVM, thresholds_keras_SVM = roc_curve(Y_test, predictions_SVM)\n",
        "# auc_keras_SVM = auc(fpr_keras_SVM, tpr_keras_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3yIm_w1bN3I"
      },
      "outputs": [],
      "source": [
        "# predictions_SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qclpudzCW4-"
      },
      "outputs": [],
      "source": [
        "# y_pred_bool = predictions_SVM.round()\n",
        "\n",
        "# print(classification_report(Y_test_SVM1, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnfLHKzzAilX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "y_pred_keras = model.predict(X_test)\n",
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_test, y_pred_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r4ylFOwC-Yy",
        "outputId": "4a86f369-4ccb-4d3a-c7ac-b43d64dee208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(203, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "(X_test).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-34mKbSBUrL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import auc\n",
        "auc_keras = auc(fpr_keras, tpr_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4tryWZvmykF"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.read_csv('/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021/NEWSTUFF_March2022/data2022_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZIjeClomynQ"
      },
      "outputs": [],
      "source": [
        "X = merged_df.drop(merged_df.columns[[0,1,2,3]], axis=1) \n",
        "Y = (merged_df['reliability']).values\n",
        "Y = Y.astype(int)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
        "\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhlRyzTfmypC"
      },
      "outputs": [],
      "source": [
        "max_fatures = 20000 #unique words, set threshold on if it appears >3 times in dataset\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ', oov_token='<unw>')\n",
        "tokenizer.fit_on_texts(merged_df['body_text_processed'].values)\n",
        "X_train_text = tokenizer.texts_to_sequences(X_train['body_text_processed'].values)\n",
        "X_train_text = pad_sequences(X_train_text, padding = 'post', maxlen = 3500) #max words in article, set to largest word count \n",
        "X_train_features = X_train.drop(X_train.columns[0], axis=1) \n",
        "X_test_text = tokenizer.texts_to_sequences(X_test['body_text_processed'].values)\n",
        "X_test_text = pad_sequences(X_test_text, padding = 'post', maxlen = 3500) #max words in article, set to largest word count \n",
        "X_test_features = X_test.drop(X_test.columns[0], axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM6MqKX9m5g6"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_PW4wg-m5kL"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021/glove.6B.100d.txt', encoding=\"utf8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLRcUfYYi2Nf"
      },
      "outputs": [],
      "source": [
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XaTZIJCm8zL"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw7GGM3Di2Sc"
      },
      "outputs": [],
      "source": [
        "#GRU\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Input, concatenate, GRU\n",
        "model8 = Sequential()\n",
        "model8.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=X_train_text.shape[1], trainable=True))\n",
        "model8.add(SpatialDropout1D(0.5))\n",
        "model8.add(Bidirectional(GRU(50)))\n",
        "#model4.add(layer = Dropout(rate = 0.5))\n",
        "model8.add(Dense(1,activation='sigmoid'))\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model8.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
        "print(model8.summary())\n",
        "#, dropout=0.4, recurrent_dropout=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWF35tMdi2ax"
      },
      "outputs": [],
      "source": [
        "H = model8.fit(x=[X_train_text], y=Y_train, epochs = 10, batch_size=64, validation_split=0.2,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpzjhw54jAfy"
      },
      "outputs": [],
      "source": [
        "X_full = tokenizer.texts_to_sequences(X['body_text_processed'].values)\n",
        "X_full = pad_sequences(X_full, padding = 'post', maxlen = 3500) #max words in article, set to largest word count \n",
        "X_full_features = X.drop(X.columns[0], axis=1) \n",
        "preds = model8.predict([X_full])\n",
        "X_full_features['pred'] = preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCuzHtn8jFFB"
      },
      "outputs": [],
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_full_features, Y, test_size=0.2, random_state=42)\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "\n",
        "model9 = XGBClassifier(silent=False, \n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 0.6,\n",
        "                      subsample = 0.6,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=300, \n",
        "                      reg_alpha = 0.9,\n",
        "                      reg_lambda = 10,\n",
        "                      max_depth=3, \n",
        "                      gamma=10, \n",
        "                      random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al7p8EXAjHD0"
      },
      "outputs": [],
      "source": [
        "model9.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\",'auc'], eval_set=eval_set, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibvLw_YQjOZR"
      },
      "outputs": [],
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model9.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "# retrieve performance metrics\n",
        "results = model9.evals_result()\n",
        "epochs = len(results['validation_0']['error'])\n",
        "x_axis = range(0, epochs)\n",
        "# plot log loss\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
        "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
        "ax.legend()\n",
        "pyplot.ylabel('Log Loss')\n",
        "pyplot.title('XGBoost Log Loss')\n",
        "pyplot.show()\n",
        "# plot classification error\n",
        "fig, ax = pyplot.subplots()\n",
        "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
        "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
        "ax.legend()\n",
        "pyplot.ylabel('Classification Error')\n",
        "pyplot.title('XGBoost Classification Error')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ7K5Kb4jYH5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "precision, recall, fscore, support = score(y_test, y_pred, average = 'binary')\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_test = model8.predict(X_test_text)\n",
        "X_test_features['pred'] = preds_test"
      ],
      "metadata": {
        "id": "tI0HDT2YLq3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFh7YwrljZiS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "y_pred_keras = model9.predict_proba(X_test_features)\n",
        "fpr_keras9, tpr_keras9, thresholds_keras9 = roc_curve(Y_test, y_pred_keras[:,1])\n",
        "auc_keras9 = auc(fpr_keras9, tpr_keras9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPQ_aJEZW4v_"
      },
      "outputs": [],
      "source": [
        "!cd '/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021'\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(fpr_keras_NB, tpr_keras_NB, label='NB (area = {:.3f})'.format(auc_keras_NB))\n",
        "plt.plot(fpr_keras_KNN, tpr_keras_KNN, label='KNN (area = {:.3f})'.format(auc_keras_KNN))\n",
        "# plt.plot(fpr_keras_SVM, tpr_keras_SVM, label='SVM (area = {:.3f})'.format(auc_keras_SVM))\n",
        "plt.plot(fpr_keras_LR, tpr_keras_LR, label='LR (area = {:.3f})'.format(auc_keras_LR))\n",
        "plt.plot(fpr_keras, tpr_keras, label='BiLSTM (area = {:.3f})'.format(auc_keras))\n",
        "plt.plot(fpr_keras1, tpr_keras1, label='CNN (area = {:.3f})'.format(auc_keras1))\n",
        "plt.plot(fpr_keras2, tpr_keras2, label='LSTM (area = {:.3f})'.format(auc_keras2))\n",
        "plt.plot(fpr_keras3, tpr_keras3, label='BiGRU (area = {:.3f})'.format(auc_keras3))\n",
        "plt.plot(fpr_keras4, tpr_keras4, label='GRU (area = {:.3f})'.format(auc_keras4))\n",
        "\n",
        "plt.plot(fpr_keras9, tpr_keras9, label='New model (area = {:.3f})'.format(auc_keras9)) #need to import model from other ipynb file\n",
        "\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best', prop={'size': 8})\n",
        "\n",
        "\n",
        "plt.savefig('/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021/DL_AUC.pdf')  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    #plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Dvyn936-Rg_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "font = {'family' : 'normal',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 16}\n",
        "\n",
        "plt.rc('font', **font)\n",
        "\n",
        "plot_confusion_matrix(cm           = np.array(confusion_matrix(Y_test, y_pred_keras[:,1].round())), \n",
        "                      normalize    = False,\n",
        "                      target_names = ['Reliable article', 'Unreliable article'],\n",
        "                      title        = \" \",\n",
        "                      cmap = 'GnBu')"
      ],
      "metadata": {
        "id": "RBV5BBVrRjuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.read_csv('/content/gdrive/Shareddrives/National Undergraduate Big Data Challenge 2021/NEWSTUFF_March2022/data2022_features.csv')"
      ],
      "metadata": {
        "id": "9v7Ddq3KV2WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "t5GqFwW2V3Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df_rel = merged_df.loc[merged_df['reliability'] == 0]"
      ],
      "metadata": {
        "id": "bqKHWw5VWFL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df_rel"
      ],
      "metadata": {
        "id": "XCx6On80WdWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model10 = XGBClassifier(silent=False, \n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 0.6,\n",
        "                      subsample = 0.6,\n",
        "                      objective='binary:logistic', \n",
        "                      n_estimators=300, \n",
        "                      reg_alpha = 0.9,\n",
        "                      reg_lambda = 10,\n",
        "                      max_depth=3, \n",
        "                      gamma=10, \n",
        "                      random_state = 42)\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(model10, X_full_features, Y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "id": "aHNfR6gQawjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import make_scorer\n",
        "specificity = make_scorer(recall_score, pos_label=0)\n",
        "results = model_selection.cross_validate(model10, X_full_features, Y, cv=10, scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'sensitivity': make_scorer(recall_score),\n",
        "    'specificity': make_scorer(recall_score,pos_label=0)\n",
        "})"
      ],
      "metadata": {
        "id": "WiCPC1ZOcMSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sensitivity = make_scorer(recall_score, pos_label=1)\n",
        "print(cross_val_score(model10, X_full_features, Y, cv=10, sensitivity))"
      ],
      "metadata": {
        "id": "SgMHSkP1cSCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['test_accuracy'].mean()"
      ],
      "metadata": {
        "id": "lfVXe8rIbogL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['test_specificity'].mean()"
      ],
      "metadata": {
        "id": "1eyL-lO9dPKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['test_sensitivity'].mean()"
      ],
      "metadata": {
        "id": "j1hksyq9dPOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Roc_curves2022Mar23.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}